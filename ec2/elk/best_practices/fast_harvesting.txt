Щоб максимально прискорити процес зчитування логів з файла за допомогою Filebeat та їх відображення в Kibana, потрібно оптимізувати налаштування всіх компонентів: Filebeat, Elasticsearch та Kibana. Ось детальний гайд:
1. Оптимізація Filebeat
Налаштування filebeat.yml:
yaml
Copy

# Збільшення буфера для зчитування логів
filebeat.inputs:
  - type: filestream
    enabled: true
    paths:
      - /var/log/*.log
    # Оптимізація швидкості зчитування:
    harvester_buffer_size: 16384  # Збільшений буфер (за замовчуванням 16KB)
    close_inactive: 5m            # Швидше закриття неактивних файлів
    scan_frequency: 1s            # Частіша перевірка нових файлів
    max_bytes: 10485760           # Макс. розмір одного логу для обробки (10MB)

# Використання прямої відправки в Elasticsearch (без Logstash для мінімальної затримки)
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  compression_level: 3           # Стиснення даних для зменшення навантаження
  worker: 8                      # Збільшення кількості потоків для паралелізму
  bulk_max_size: 8192            # Максимальний розмір пачки даних для відправки
  timeout: 60s                   # Таймаут для відповіді Elasticsearch

# Вимкнення непотрібних функцій:
queue.mem:
  events: 4096                   # Розмір черги в оперативній пам'яті
  flush.min_events: 2048         # Мінімальна кількість подій для відправки
processors:
  - drop_fields:                 # Видалення непотрібних полів
      fields: ["log.offset", "input.type"]

2. Оптимізація Elasticsearch
Налаштування індексу для швидкої індексації:
json
Copy

PUT /filebeat-logs
{
  "settings": {
    "index": {
      "number_of_shards": 3,               // Залежить від кількості нод
      "number_of_replicas": 0,             // Вимкнути репліки під час індексації
      "refresh_interval": "30s",           // Рідше оновлення для зменшення навантаження
      "translog.durability": "async",      // Асинхронна запис транзакцій
      "translog.sync_interval": "30s"      // Інтервал синхронізації транзакцій
    }
  }
}

Після завершення індексації:
json
Copy

POST /filebeat-logs/_settings
{
  "index": {
    "number_of_replicas": 1,      // Увімкнути репліки для відмовостійкості
    "refresh_interval": "1s"      // Повернути частоту оновлення
  }
}

3. Оптимізація Kibana
Для швидкого відображення:

    Кешування даних:

        Увімкніть кешування в браузері (налаштування кешування HTTP-відповідей на сервері Kibana).

        Використовуйте Time Filter для обмеження даних до актуального періоду (наприклад, останні 15 хвилин).

    Оптимізація запитів:

        Використовуйте Runtime Fields для обчислення полей "на льоту" без зміни індексу.

        Уникайте складних агрегацій на великих наборах даних.

    Налаштування індекс-патернів:
    json
    Copy

    PUT /_index_template/filebeat-template
    {
      "index_patterns": ["filebeat-*"],
      "template": {
        "settings": {
          "index.codec": "best_compression",  // Стиснення даних
          "index.query.default_field": ["message"]  // Пришвидшення пошуку
        }
      }
    }

4. Додаткові поради

    Апаратні ресурси:

        Використовуйте SSD-диски для Elasticsearch (особливо для швидких операцій запису).

        Збільшіть HEAP пам'ять для Elasticsearch (до 50% від доступної RAM, але не більше 32GB).

    Мережа:

        Переконайтеся, що Filebeat і Elasticsearch знаходяться в одній мережі (мінімальний ping).

        Використовуйте dedicated network interfaces для трафіку Elasticsearch.

    Моніторинг:

        Увімкніть Monitoring в Kibana для аналізу вузьких місць (наприклад, затримки в чергах Filebeat).

5. Приклад пайплайну для максимальної швидкості

    Filebeat зчитує логи зі збільшеним буфером (harvester_buffer_size).

    Дані стискаються та відправляються в Elasticsearch пачками (bulk_max_size).

    Elasticsearch індексує дані з тимчасово вимкненими репліками та рідкими оновленнями.

    Kibana відображає дані з обмеженим часовим діапазоном та кешуванням.

Якщо потрібно ще більше прискорити процес, можна:

    Використовувати Hot-Warm архітектуру для розділення індексів на "гарячі" та "холодні".

    Вимкнути аналіз полів, які не використовуються в пошуку (наприклад, "index": false у мапінгу).
